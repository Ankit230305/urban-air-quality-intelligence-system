from __future__ import annotations

import json, os, glob
from pathlib import Path
from typing import Dict, Optional, Tuple, List

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st


# ---- Page setup ----
def _show_recommendations(df: 'pd.DataFrame'):
    try:
        pm = float(df["pm2_5"].median(skipna=True)) if "pm2_5" in df else float("nan")
    except Exception:
        pm = float("nan")
    aqi_cat = None
    if "aqi_category" in df and df["aqi_category"].notna().any():
        try:
            aqi_cat = df["aqi_category"].mode().iloc[0]
        except Exception:
            aqi_cat = None
    elderly = None
    if "pct_elderly" in df:
        try:
            elderly = float(df["pct_elderly"].median(skipna=True))
        except Exception:
            elderly = None
    advice = []
    if (aqi_cat in ["Unhealthy","Very Unhealthy","Hazardous"]) or (not np.isnan(pm) and pm >= 100):
        advice.append("Limit outdoor activity; wear N95 outdoors; prefer public transport over driving.")
    if elderly is not None and elderly >= 9.0:
        advice.append("High elderly share: push targeted alerts to clinics and senior housing.")
    if "wind_speed" in df and pd.to_numeric(df["wind_speed"], errors="coerce").median(skipna=True) < 2:
        advice.append("Low wind: pollutants may stagnateâ€”use filtration indoors.")
    if not advice:
        advice.append("Air quality looks acceptable. Maintain normal activities and monitor updates.")
    import streamlit as st
    st.info("**Recommendations:** " + "  â€¢  ".join(advice))

st.set_page_config(page_title="Urban Air Quality Intelligence System",
                   layout="wide",
                   page_icon="ðŸŒ«ï¸")

# ---- Cities we support out of the box (add more here if you want) ----
CITY_OPTS = [
    "Delhi", "Mumbai", "Bengaluru", "Chennai", "Hyderabad", "Kolkata", "Vizag", "Vellore"
]


# ---- Utilities ----
def slug_base(city: str) -> str:
    """kebab for file matching without trailing underscores."""
    return city.lower().replace(" ", "_")


def _first_existing(paths: List[Path]) -> Optional[Path]:
    for p in paths:
        if p.exists():
            return p
    return None


def find_city_files(city: str) -> Dict[str, Optional[Path]]:
    """
    Locate all artifacts for a city, supporting both single '_' and double '__' patterns
    and city-specific or generic forecast file.
    """
    s = slug_base(city)
    processed = sorted(
        [Path(p) for p in glob.glob(f"data/processed/*{s}*features_plus_demo.csv")],
        key=lambda p: p.stat().st_mtime if p.exists() else 0,
        reverse=True,
    )
    anomalies = sorted(
        [Path(p) for p in glob.glob(f"data/processed/*{s}*_anomalies.csv")],
        key=lambda p: p.stat().st_mtime if p.exists() else 0,
        reverse=True,
    )
    health = sorted(
        [Path(p) for p in glob.glob(f"data/processed/*{s}*_health.csv")],
        key=lambda p: p.stat().st_mtime if p.exists() else 0,
        reverse=True,
    )

    forecast = _first_existing([
        Path(f"models/forecast_pm25_{s}.csv"),
        Path("models/forecast_pm25.csv"),
        Path(f"models/forecast_pm25_{s.rstrip('_')}.csv"),
    ])

    seasonal = _first_existing([Path(f"reports/seasonal_{s}.csv")])
    assoc = _first_existing([Path(f"reports/assoc_rules_{s}.csv")])
    patterns_md = _first_existing([Path(f"reports/patterns_{s}.md")])

    metrics = _first_existing([Path(f"models/supervised_metrics_{s}.json")])

    return {
        "processed": processed[0] if processed else None,
        "anomalies": anomalies[0] if anomalies else None,
        "health": health[0] if health else None,
        "forecast": forecast,
        "seasonal": seasonal,
        "assoc": assoc,
        "patterns_md": patterns_md,
        "metrics": metrics,
    }


@st.cache_data(show_spinner=False)
def read_csv(path: str | Path, parse_dates: Tuple[str, ...] = ("datetime",)) -> pd.DataFrame:
    df = pd.read_csv(path)
    for c in parse_dates:
        if c in df.columns:
            df[c] = pd.to_datetime(df[c], errors="coerce")
            # normalize tz -> naive UTC
            if hasattr(df[c].dtype, "tz") and df[c].dt.tz is not None:
                df[c] = df[c].dt.tz_convert("UTC").dt.tz_localize(None)
    # numeric coercion for common cols
    for c in ["pm2_5","pm10","no2","o3","so2","co","temp","humidity","wind_speed","precip","aqi"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def get_forecast_df(p: Optional[Path]) -> pd.DataFrame:
    if not p:
        return pd.DataFrame()
    f = pd.read_csv(p)
    # try to detect time column
    for tc in ["ds", "datetime", "date", "time", "timestamp"]:
        if tc in f.columns:
            f[tc] = pd.to_datetime(f[tc], errors="coerce")
            f = f.rename(columns={tc: "ds"})
            break
    if "ds" not in f.columns:
        return pd.DataFrame()
    # unify yhat name if present
    if "yhat" not in f.columns:
        # Prophet-style sometimes: 'yhat', or custom: 'forecast'
        for yc in ["forecast", "y_pred", "pm25_pred", "pm2_5_pred"]:
            if yc in f.columns:
                f = f.rename(columns={yc: "yhat"})
                break
    return f.sort_values("ds")


def corr_heatmap(df: pd.DataFrame):
    num = df.select_dtypes(include=[np.number])
    if num.empty:
        st.info("Not enough numeric data to plot correlations.")
        return
    corr = num.corr(numeric_only=True)
    fig = px.imshow(corr, text_auto=True, aspect="auto", title="Correlation heatmap")
    st.plotly_chart(fig, use_container_width=True)


def nice_metric_table(d: Dict) -> pd.DataFrame:
    """
    Convert metrics JSON structure to two flat tables (regression & classification).
    """
    if not d:
        return pd.DataFrame()
    # regression: dict[model] -> {MAE, RMSE, R2}
    if "regression" in d and isinstance(d["regression"], dict):
        reg_rows = []
        for model, vals in d["regression"].items():
            row = {"Model": model}
            row.update(vals)
            reg_rows.append(row)
        reg_df = pd.DataFrame(reg_rows)
    else:
        reg_df = pd.DataFrame()

    if "classification" in d and isinstance(d["classification"], dict):
        cls_rows = []
        for model, vals in d["classification"].items():
            row = {"Model": model}
            row.update(vals)
            cls_rows.append(row)
        cls_df = pd.DataFrame(cls_rows)
    else:
        cls_df = pd.DataFrame()

    return reg_df, cls_df


# ---- Sidebar ----
st.sidebar.markdown("## Urban Air Quality Intelligence System")
city = st.sidebar.selectbox("City", CITY_OPTS, index=CITY_OPTS.index("Kolkata") if "Kolkata" in CITY_OPTS else 0)
st.sidebar.caption("Switch the city to update all views.")

# convenience actions
if st.sidebar.button("Clear data cache"):
    st.cache_data.clear()
    st.sidebar.success("Cache cleared. Data will reload on next run.")

files = find_city_files(city)
st.sidebar.write("**Data files found:**")
for k, v in files.items():
    icon = "âœ…" if v else "âŒ"
    st.sidebar.write(f"{icon} {k}: {v.name if v else 'missing'}")

# ---- Page Title ----
st.title(f"ðŸŒ«ï¸ Urban Air Quality â€” {city}")

# ---- Load processed for EDA ----
if not files["processed"]:
    st.warning("No processed dataset found for this city. Run your pipeline, then refresh.")
    st.stop()

df = read_csv(files["processed"])
df = df.sort_values("datetime")

# Date filter (computed from data itself)
min_d = pd.to_datetime(df["datetime"].min()).date() if not df.empty else None
max_d = pd.to_datetime(df["datetime"].max()).date() if not df.empty else None
date_range = st.date_input(
    "Filter date range",
    value=(min_d, max_d) if min_d and max_d else None,
    min_value=min_d, max_value=max_d
)

if isinstance(date_range, tuple) and len(date_range) == 2 and date_range[0] and date_range[1]:
    start, end = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
    m = (df["datetime"] >= start) & (df["datetime"] <= end + pd.Timedelta(days=1))
    df = df.loc[m].copy()

# ---- KPI row ----
kpi_cols = st.columns(5)
def _metric(val, label, col):
    if val is None or np.isnan(val):
        col.metric(label, "â€”")
    else:
        col.metric(label, f"{val:.1f}")

_metric(df["pm2_5"].mean(skipna=True), "Avg PM2.5", kpi_cols[0])
_metric(df["pm10"].mean(skipna=True),  "Avg PM10",  kpi_cols[1])
_metric(df["o3"].mean(skipna=True),    "Avg Oâ‚ƒ",    kpi_cols[2])
_metric(df["no2"].mean(skipna=True),   "Avg NOâ‚‚",   kpi_cols[3])
_metric(df["aqi"].mean(skipna=True) if "aqi" in df else np.nan, "Avg AQI", kpi_cols[4])

st.markdown("---")

# ---- Tabs ----
tab_eda, tab_patterns, tab_models, tab_forecast, tab_anoms, tab_health = st.tabs(
    ["EDA", "Patterns", "Models", "Forecast", "Anomalies", "Health"]
)

with tab_eda:
    st.subheader("Exploratory Data Analysis")
    # choose pollutants to plot
    poll_cols = [c for c in ["pm2_5","pm10","no2","o3","so2","co"] if c in df.columns]
    if not poll_cols:
        st.info("No pollutant columns found.")
    else:
        selected = st.multiselect("Select pollutants to plot", poll_cols, default=["pm2_5","pm10"][:len(poll_cols)])
        if selected:
            fig = px.line(df, x="datetime", y=selected, title="Hourly pollutants")
            st.plotly_chart(fig, use_container_width=True)

    # AQI category distribution
    if "aqi_category" in df.columns and df["aqi_category"].notna().any():
        counts = (df["aqi_category"].value_counts().rename_axis("AQI Category")
                  .reset_index(name="count"))
        st.plotly_chart(px.bar(counts, x="AQI Category", y="count", title="AQI category counts"),
                        use_container_width=True)

    st.markdown("#### Correlations")
    corr_heatmap(df)

with tab_patterns:
    st.subheader("Pollution Pattern Discovery")
    dpath, rpath = files["seasonal"], files["assoc"]

    if dpath and dpath.exists():
        daily = read_csv(dpath, parse_dates=("datetime",))
        st.caption(f"Daily seasonal table â€” rows: {len(daily)}")
        if "cluster" in daily.columns:
            st.plotly_chart(
                px.scatter(daily, x="datetime", y="pm2_5" if "pm2_5" in daily else daily.select_dtypes(np.number).columns[0],
                           color="cluster", title="Daily PM2.5 (or first numeric) with clusters"),
                use_container_width=True,
            )
        st.dataframe(daily.tail(30), use_container_width=True)
    else:
        st.info("No seasonal daily file found.")

    if rpath and rpath.exists():
        # assoc rules can be big; preview top
        rules = pd.read_csv(rpath).sort_values("lift", ascending=False)
        st.markdown("**Top association rules (by lift)**")
        st.dataframe(rules.head(50), use_container_width=True)
        st.caption(f"Full rules file: {rpath.name} ({rpath.stat().st_size/1e6:.1f} MB)")
    else:
        st.info("No association rules file found.")

with tab_models:
    st.subheader("Supervised Models â€” Scores & Comparison")
    mfile = files["metrics"]
    if not mfile:
        st.info("No metrics JSON found.")
    else:
        try:
            m = json.loads(Path(mfile).read_text())
        except Exception as e:
            st.error(f"Failed to read metrics: {e}")
            m = {}

        reg_df, cls_df = nice_metric_table(m)

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**Regression (PM2.5)**")
            if not reg_df.empty:
                st.dataframe(reg_df, use_container_width=True)
                if {"Model","R2"}.issubset(reg_df.columns):
                    st.plotly_chart(px.bar(reg_df, x="Model", y="R2", title="RÂ² by model"),
                                    use_container_width=True)
            else:
                st.info("Regression metrics missing.")

        with c2:
            st.markdown("**Classification (AQI category)**")
            if not cls_df.empty:
                st.dataframe(cls_df, use_container_width=True)
                if {"Model","accuracy"}.issubset(cls_df.columns):
                    st.plotly_chart(px.bar(cls_df, x="Model", y="accuracy", title="Accuracy by model"),
                                    use_container_width=True)
            else:
                st.info("Classification metrics missing.")

with tab_forecast:
    st.subheader("7-day PM2.5 Forecast (Prophet)")
    fdf = get_forecast_df(files["forecast"])
    if fdf.empty:
        st.info("No forecast file found.")
    else:
        # show forecast line
        ycol = "yhat" if "yhat" in fdf.columns else (fdf.select_dtypes(np.number).columns[0] if len(fdf.select_dtypes(np.number).columns) else None)
        if ycol:
            fig = px.line(fdf, x="ds", y=ycol, title="Forecasted PM2.5")
            st.plotly_chart(fig, use_container_width=True)
        st.dataframe(fdf.tail(50), use_container_width=True)

with tab_anoms:
    st.subheader("Anomaly Detection â€” Spikes / Outliers")
    apath = files["anomalies"]
    if apath and apath.exists():
        adf = read_csv(apath, parse_dates=("datetime",))
        st.dataframe(adf.tail(100), use_container_width=True)
        # quick line with anomaly markers if available
        y = "pm2_5" if "pm2_5" in adf else (adf.select_dtypes(np.number).columns[0] if len(adf.select_dtypes(np.number).columns) else None)
        if y:
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=adf["datetime"], y=adf[y], mode="lines", name=y))
            if "is_anomaly" in adf.columns:
                mask = adf["is_anomaly"] == 1
                fig.add_trace(go.Scatter(x=adf.loc[mask, "datetime"],
                                         y=adf.loc[mask, y],
                                         mode="markers", name="anomaly"))
            fig.update_layout(title="Signal with anomalies")
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("No anomalies file found.")

with tab_health:
    st.subheader("Health Risk â€” Vulnerable Population Estimate")
    hpath = files["health"]
    if hpath and hpath.exists():
        hdf = read_csv(hpath, parse_dates=("datetime",))
        st.dataframe(hdf.tail(100), use_container_width=True)
        # if a risk column exists, show quick chart
        for candidate in ["risk_score", "resp_prob", "respiratory_risk", "hospital_admissions_est"]:
            if candidate in hdf.columns:
                st.plotly_chart(px.line(hdf, x="datetime", y=candidate, title=candidate.replace("_"," ").title()),
                                use_container_width=True)
                break
    else:
        st.info("No health file found.")

st.caption("Tip: Use the city selector in the sidebar. The app automatically reloads when you change it.")
